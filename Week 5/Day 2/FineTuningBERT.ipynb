{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "58e2353e-acaa-4b3f-8eac-1a936da206fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d5ecde08-d2c4-43dc-9cc9-858782704931",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of AlbertForQuestionAnswering were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Fix symlink warning for Windows users\n",
    "os.environ[\"HF_HUB_DISABLE_SYMLINKS_WARNING\"] = \"1\"\n",
    "\n",
    "# Load ALBERT model for Question Answering\n",
    "model_name = \"albert-base-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f77d10ee-c190-46ed-bf35-1d12d4c8f2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset (Ensure correct formatting)\n",
    "data = [\n",
    "    {\"context\": \"My name is Ramzan.\", \"question\": \"What is my name?\", \"answer\": \"Ramzan\", \"start\": 11, \"end\": 17},\n",
    "    {\"context\": \"I live in Lahore.\", \"question\": \"Where do you live?\", \"answer\": \"Lahore\", \"start\": 10, \"end\": 16},\n",
    "    {\"context\": \"My occupation is Engineer.\", \"question\": \"What is your occupation?\", \"answer\": \"Engineer\", \"start\": 17, \"end\": 25},\n",
    "    {\"context\": \"I work at ML1.\", \"question\": \"Where do you work?\", \"answer\": \"ML1\", \"start\": 10, \"end\": 13},\n",
    "    {\"context\": \"I study at UCP.\", \"question\": \"Where do you study?\", \"answer\": \"UCP\", \"start\": 11, \"end\": 14},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a67a6ecf-499d-462d-8236-f591b83ab215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Dataset Class\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=384):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        inputs = self.tokenizer(\n",
    "            item['question'],\n",
    "            item['context'],\n",
    "            truncation=\"only_second\",\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\",\n",
    "            return_offsets_mapping=True  # Needed for correct token mapping\n",
    "        )\n",
    "\n",
    "        # Extract token positions correctly\n",
    "        offset_mapping = inputs[\"offset_mapping\"].squeeze()\n",
    "        start_pos = next((i for i, (start, end) in enumerate(offset_mapping) if start <= item['start'] < end), 0)\n",
    "        end_pos = next((i for i, (start, end) in enumerate(offset_mapping) if start < item['end'] <= end), 1)\n",
    "\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'].squeeze(),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(),\n",
    "            'start_positions': torch.tensor(start_pos),\n",
    "            'end_positions': torch.tensor(end_pos)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e92d8503-06e1-4179-9d55-a2cc2241e18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Dataset & DataLoader\n",
    "dataset = QADataset(data, tokenizer)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "fa23aff8-3409-47cb-805f-2d39f3acd0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/3: 100%|██████████| 3/3 [00:17<00:00,  5.97s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3 - Loss: 5.953663508097331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/3: 100%|██████████| 3/3 [00:16<00:00,  5.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/3 - Loss: 2.822128931681315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 3/3: 100%|██████████| 3/3 [00:16<00:00,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/3 - Loss: 0.8069224754969279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Training setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Training Loop\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch in tqdm(dataloader, desc=f\"Training Epoch {epoch + 1}/{epochs}\"):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        start_pos = batch['start_positions'].to(device)\n",
    "        end_pos = batch['end_positions'].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            start_positions=start_pos,\n",
    "            end_positions=end_pos\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Prevent exploding gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {running_loss / len(dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "44b8b7cf-757a-4636-8822-7b3806b9ca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Inference Function\n",
    "def ask_question(question, context):\n",
    "    inputs = tokenizer(\n",
    "        question,\n",
    "        context,\n",
    "        truncation=\"only_second\",\n",
    "        max_length=384,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # Get answer span\n",
    "    answer_start = torch.argmax(outputs.start_logits)\n",
    "    answer_end = torch.argmax(outputs.end_logits) + 1\n",
    "\n",
    "    # Convert tokens to answer text\n",
    "    answer = tokenizer.convert_tokens_to_string(\n",
    "        tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0][answer_start:answer_end])\n",
    "    )\n",
    "    \n",
    "    return answer.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "448fb6f4-e0d8-4895-bcbd-6542a9b4cf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Where do you live?\n",
      "Answer: you live\n"
     ]
    }
   ],
   "source": [
    "# Test the model with a question\n",
    "context = \"I live in Lahore.\"\n",
    "question = \"Where do you live?\"\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {ask_question(question, context)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6893710-0c18-43a3-bd93-02b91feacd30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
